{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc22a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc72499903d45968918a4cf95238d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 104)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from modules import CodeARmodel, VQVAE\n",
    "import random\n",
    "import hparams as hp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "GAP_TIME = 6\n",
    "WINDOW_SIZE = 24\n",
    "ID_COLS = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "DATA_FILEPATH = \"./Dataset/all_hourly_data.h5\"\n",
    "\n",
    "X = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "statics = pd.read_hdf(DATA_FILEPATH, 'patients')\n",
    "Y = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Y['los_3'] = Y['los_icu'] > 3\n",
    "Y['los_7'] = Y['los_icu'] > 7\n",
    "Y.drop(columns=['los_icu'], inplace=True)\n",
    "Y.astype(float)\n",
    "\n",
    "df_X, df_Y = aggregate_data(X, Y)\n",
    "\n",
    "train_frac, dev_frac, test_frac = 0.8, 0.1, 0.1\n",
    "X_subj_idx, Y_subj_idx = [df.index.get_level_values('subject_id') for df in (df_X, df_Y)]\n",
    "X_subjects = set(X_subj_idx)\n",
    "assert X_subjects == set(Y_subj_idx), \"Subject ID pools differ!\"\n",
    "\n",
    "np.random.seed(0)\n",
    "subjects, N = np.random.permutation(list(X_subjects)), len(X_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "[(df_X_train, df_X_dev, df_X_test), (df_Y_train, df_Y_dev, df_Y_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (df_X, df_Y)\n",
    "]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "df_X_means = np.nanmean(df_X_train.loc[:, idx[:, ['mean']]].to_numpy(), axis=0)\n",
    "df_X_stds = np.nanstd(df_X_train.loc[:, idx[:, ['mean']]].to_numpy(), axis=0)\n",
    "\n",
    "if not os.path.exists(f\"./synthetic_dataset/codear\"):\n",
    "    os.mkdir(f\"./synthetic_dataset/codear\")\n",
    "    os.mkdir(f\"./synthetic_dataset/codear/sequences\")\n",
    "    os.mkdir(f\"./synthetic_dataset/codear/labels\")\n",
    "\n",
    "model = CodeARmodel(hp).cuda()\n",
    "checkpoint_dict = torch.load(f\"./training_log/codear/Gen_checkpoint_149000.pt\", map_location='cpu')\n",
    "model.load_state_dict(checkpoint_dict['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "vqvae = VQVAE(hp).cuda()\n",
    "vqvae.load_state_dict(torch.load(f\"./training_log/codear/vqvae.pt\", map_location='cpu'))\n",
    "vqvae.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k, subj in enumerate(tqdm_notebook(X_subjects)):\n",
    "        label = torch.LongTensor(df_Y[df_Y.index.get_level_values('subject_id')==subj].astype(int).to_numpy())\n",
    "        code = model.inference(label.cuda())\n",
    "        preds = vqvae.decode(code)\n",
    "        seq = df_X_stds*preds[0].detach().cpu().numpy()+df_X_means\n",
    "        if k==0:\n",
    "            print(seq.shape)\n",
    "            print()\n",
    "\n",
    "        if not os.path.exists(f\"./Dataset/codes/codear\"):\n",
    "            os.mkdir(f\"./Dataset/codes/codear\")\n",
    "\n",
    "        np.save(f\"./Dataset/codes/codear/codes_{subj}.npy\", code[0].detach().cpu().numpy())\n",
    "        np.save(f\"./synthetic_dataset/codear/sequences/{subj}.npy\", seq)\n",
    "        np.save(f\"./synthetic_dataset/codear/labels/{subj}.npy\", label[0]) # [4, ] (4-tasks)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IITP_MED] *",
   "language": "python",
   "name": "conda-env-IITP_MED-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
